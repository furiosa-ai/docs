<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Release Notes - 0.10.0 &mdash; Furiosa SDK Documentation 0.10.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Release Notes - 0.9.0" href="0.9.0.html" />
    <link rel="prev" title="furiosa.serving.processors package" href="../api/python/furiosa.serving.processors.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Furiosa SDK Documentation
          </a>
              <div class="version">
                0.10.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">FuriosaAI NPU</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../npu/warboy.html">FuriosaAI Warboy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FuriosaAI Software</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../software/intro.html">FuriosaAI SW Stack Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/installation.html">Driver, Firmware, and Runtime Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/python-sdk.html">Python SDK installation and user guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/c-sdk.html">C SDK installation and user guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/cli.html">Command Line Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/compiler.html">Compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/quantization.html">Model Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/performance.html">Performance Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/profiler.html">Performance Profiling</a></li>
<li class="toctree-l1"><a class="reference external" href="https://furiosa-ai.github.io/furiosa-models/latest/">FuriosaAI Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/serving.html">Model Server (Serving Framework)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/kubernetes_support.html">Kubernetes Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/vm_support.html">Configuring Warboy Pass-through for Virtual Machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/tutorials.html">Tutorial and Code Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/references.html">References</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Release Notes</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Release Notes - 0.10.0</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#installing-the-latest-sdk-or-upgrading">Installing the latest SDK or Upgrading</a></li>
<li class="toctree-l2"><a class="reference internal" href="#major-changes">Major changes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#next-generation-runtime-engine-furiosart">Next Generation Runtime Engine, FuriosaRT</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-server-and-serving-framework">Model Server and Serving Framework</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-quantization-tool">Model Quantization Tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiler">Compiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-profiler">Performance Profiler</a></li>
<li class="toctree-l3"><a class="reference internal" href="#furiosa-litmus">furiosa-litmus</a></li>
<li class="toctree-l3"><a class="reference internal" href="#new-benchmark-tool-furiosa-bench">New Benchmark Tool ‘furiosa-bench’</a></li>
<li class="toctree-l3"><a class="reference internal" href="#furiosa-toolkit">furiosa-toolkit</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="0.9.0.html">Release Notes - 0.9.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.8.0.html">Release Notes - 0.8.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.7.0.html">Release Notes - 0.7.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.6.0.html">Release Notes - 0.6.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.5.0.html">Release Notes - 0.5.0</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Customer Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://furiosa-ai.atlassian.net/servicedesk/customer/portals/">FuriosaAI Customer Center</a></li>
<li class="toctree-l1"><a class="reference internal" href="../customer-support/bugs.html">Bug Report</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Previous Documents</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://furiosa-ai.github.io/docs/v0.9.0/en/">v0.9.0</a></li>
<li class="toctree-l1"><a class="reference external" href="https://furiosa-ai.github.io/docs/v0.8.0/en/">v0.8.0</a></li>
<li class="toctree-l1"><a class="reference external" href="https://furiosa-ai.github.io/docs/v0.6.0/en/">v0.6.0</a></li>
<li class="toctree-l1"><a class="reference external" href="https://furiosa-ai.github.io/docs/v0.5.0/en/">v0.5.0</a></li>
<li class="toctree-l1"><a class="reference external" href="https://furiosa-ai.github.io/docs/v0.2.0/en/">v0.2.0</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Furiosa SDK Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Release Notes - 0.10.0</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/releases/0.10.0.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="release-notes-0-10-0">
<h1>Release Notes - 0.10.0<a class="headerlink" href="#release-notes-0-10-0" title="Permalink to this heading"></a></h1>
<p>Furiosa SDK 0.10.0 is a major release which includes the followings:</p>
<ul class="simple">
<li><p>Adds the next generation runtime engine (FuriosaRT) with higher performance and multi-device features</p></li>
<li><p>Improves usability of optimization for vision models by removing quantization operators from models</p></li>
<li><p>Supports OpenMetrics format in Metrics Exporter and provide more metrics such as NPU utilization</p></li>
<li><p>Improves furiosa-litmus to collect and dump from the diagnosis steps for reporting</p></li>
<li><p>Removes Python dependencies from <code class="docutils literal notranslate"><span class="pre">furiosa-compiler</span></code> command</p></li>
<li><p>Adds the new benchmark tool <code class="docutils literal notranslate"><span class="pre">furiosa-bench</span></code></p></li>
</ul>
<p>This release also includes a number of other feature additions, bug fixes, and performance improvements.</p>
<table class="docutils align-default" id="id2">
<caption><span class="caption-text">Component versions</span><a class="headerlink" href="#id2" title="Permalink to this table"></a></caption>
<colgroup>
<col style="width: 80%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Package Name</p></th>
<th class="head"><p>Version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>NPU Driver</p></td>
<td><p>1.9.2</p></td>
</tr>
<tr class="row-odd"><td><p>NPU Firmware Tools</p></td>
<td><p>1.5.1</p></td>
</tr>
<tr class="row-even"><td><p>NPU Firmware Image</p></td>
<td><p>1.7.3</p></td>
</tr>
<tr class="row-odd"><td><p>HAL (Hardware Abstraction Layer)</p></td>
<td><p>0.11.0</p></td>
</tr>
<tr class="row-even"><td><p>Furiosa Compiler</p></td>
<td><p>0.10.0</p></td>
</tr>
<tr class="row-odd"><td><p>Furiosa Quantizer</p></td>
<td><p>0.10.0</p></td>
</tr>
<tr class="row-even"><td><p>Furiosa Runtime</p></td>
<td><p>0.10.0</p></td>
</tr>
<tr class="row-odd"><td><p>Python SDK (furiosa-server, furiosa-serving, ..)</p></td>
<td><p>0.10.0</p></td>
</tr>
<tr class="row-even"><td><p>NPU Toolkit (furiosactl)</p></td>
<td><p>0.11.0</p></td>
</tr>
<tr class="row-odd"><td><p>NPU Device Plugin</p></td>
<td><p>0.10.1</p></td>
</tr>
<tr class="row-even"><td><p>NPU Feature Discovery</p></td>
<td><p>0.2.0</p></td>
</tr>
</tbody>
</table>
<section id="installing-the-latest-sdk-or-upgrading">
<h2>Installing the latest SDK or Upgrading<a class="headerlink" href="#installing-the-latest-sdk-or-upgrading" title="Permalink to this heading"></a></h2>
<p>If you are using APT repository, the upgrade process is simple.
Please run as follows. If you are not familiar with how to use FurioaAI’s APT repository,
please find more detais from <a class="reference internal" href="../software/installation.html#requiredpackages"><span class="std std-ref">Driver, Firmware, and Runtime Installation</span></a>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>apt-get<span class="w"> </span>upgrade
</pre></div>
</div>
<p>You can also upgrade specific packages as follows:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>furiosa-driver-warboy<span class="w"> </span>furiosa-libnux
</pre></div>
</div>
<p>You can upgrade firmware as follows:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>apt-get<span class="w"> </span>update<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="se">\</span>
apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>furiosa-firmware-tools<span class="w"> </span>furiosa-firmware-image
</pre></div>
</div>
<p>You can upgrade Python package as follows:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip<span class="w"> </span>setuptools<span class="w"> </span>wheel
pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>furiosa-sdk
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When installing or upgrading the furiosa-sdk without updating pip to the latest version,
you may encounter the following errors.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>ERROR:<span class="w"> </span>Could<span class="w"> </span>not<span class="w"> </span>find<span class="w"> </span>a<span class="w"> </span>version<span class="w"> </span>that<span class="w"> </span>satisfies<span class="w"> </span>the<span class="w"> </span>requirement<span class="w"> </span>furiosa-quantizer-impl<span class="o">==</span><span class="m">0</span>.9.*<span class="w"> </span><span class="o">(</span>from<span class="w"> </span>furiosa-quantizer<span class="o">==</span><span class="m">0</span>.9.*-&gt;furiosa-sdk<span class="o">)</span><span class="w"> </span><span class="o">(</span>from<span class="w"> </span>versions:<span class="w"> </span>none<span class="o">)</span>
ERROR:<span class="w"> </span>No<span class="w"> </span>matching<span class="w"> </span>distribution<span class="w"> </span>found<span class="w"> </span><span class="k">for</span><span class="w"> </span>furiosa-quantizer-impl<span class="o">==</span><span class="m">0</span>.9.*<span class="w"> </span><span class="o">(</span>from<span class="w"> </span>furiosa-quantizer<span class="o">==</span><span class="m">0</span>.9.*-&gt;furiosa-sdk<span class="o">)</span>
</pre></div>
</div>
</div>
</section>
<section id="major-changes">
<h2>Major changes<a class="headerlink" href="#major-changes" title="Permalink to this heading"></a></h2>
<section id="next-generation-runtime-engine-furiosart">
<h3>Next Generation Runtime Engine, FuriosaRT<a class="headerlink" href="#next-generation-runtime-engine-furiosart" title="Permalink to this heading"></a></h3>
<p>SDK 0.10.0 includes the next-generation runtime engine called <cite>FuriosaRT</cite>.
FuriosaRT is a newly designed runtime library that offers more advanced features and
high performance in various workloads.
Many components, such as furiosa-litmus, furiosa-bench, and furiosa-seving,
are based on FuriosaRT, and the benefits of the new runtime engine are reflected in these components.
FuriosaRT provides the backward compatibility with the previous runtime and
includes the following new features:</p>
<section id="new-runtime-api">
<h4>New Runtime API<a class="headerlink" href="#new-runtime-api" title="Permalink to this heading"></a></h4>
<p>FuriosaRT introduces a native asynchronous
API based on Python’s asyncio &lt;<a class="reference external" href="https://docs.python.org/3/library/asyncio.html">https://docs.python.org/3/library/asyncio.html</a>&gt;.
The existing APIs were sufficient for batch applications,
but it requires extra code to implement high-performance serving applications,
handling many concurrent individual requests. The new API natively supports asynchronous execution.
With the new API, users can easily write their applications running on existing web frameworks
such as <a class="reference external" href="https://fastapi.tiangolo.com/">FastAPI</a></p>
<p>The new API introduced many advanced features, and you can learn more about the details at
<a class="reference external" href="https://furiosa-ai.github.io/docs/v0.10.0/en/api/python/furiosa.runtime.html">Furiosa SDK API Reference - furiosa.runtime</a></p>
</section>
<section id="multi-device-support-and-improvement-on-device-configuration">
<span id="release-0-10-0-deviceselector"></span><h4>Multi-device Support and Improvement on Device Configuration<a class="headerlink" href="#multi-device-support-and-improvement-on-device-configuration" title="Permalink to this heading"></a></h4>
<p>FuriosaRT natively supports multiple devices with a single session. This feature leads
to high-performance inference using multiple devices without extra implementations.
Furthermore, FuriosaRT adopts more abstracted way to specify NPU devices.
Before 0.9.0 release, users used to set device file names (e.g., <code class="docutils literal notranslate"><span class="pre">npu0pe0-1</span></code>) explicitly
in the environment variable <code class="docutils literal notranslate"><span class="pre">NPU_DEVNAME</span></code> or  <code class="docutils literal notranslate"><span class="pre">session.create(..,</span> <span class="pre">device=”..”)</span></code>.
This way was inconvinient in many cases because users need
to find all available device files and specify them manually.</p>
<p>FuriosaRT allows users to specify NPU arch, count of NPUs in a textutal representation.
This representation is allowed in the new environment variable <code class="docutils literal notranslate"><span class="pre">FURIOSA_DEVICES</span></code> as follows:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">FURIOSA_DEVICES</span><span class="o">=</span><span class="s2">&quot;warboy(2)*8&quot;</span>
</pre></div>
</div>
<p>The above example lets FuriosaRT to find 8 Warboys, each of which is configured as two PEs fusion in the system.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">FURIOSA_DEVICES</span><span class="o">=</span><span class="s2">&quot;npu:0:0-1,npu:1:0-1&quot;</span>
</pre></div>
</div>
<p>For backward compatibility, FuriosaRT still supports <code class="docutils literal notranslate"><span class="pre">NPU_DEVNAME</span></code> environment variable.
However, <code class="docutils literal notranslate"><span class="pre">NPU_DEVNAME</span></code> will be deprecated in a future release.</p>
<p>You can find more details about the device configuration at
<a class="reference external" href="https://furiosa-ai.github.io/docs/v0.10.0/en/api/python/furiosa.runtime.html#device-specification">Furiosa SDK API Reference - Device Specification</a>.</p>
</section>
<section id="higher-throughput">
<h4>Higher Throughput<a class="headerlink" href="#higher-throughput" title="Permalink to this heading"></a></h4>
<p>According to our benchmark, FuriosaRT shows significantly improved throughput
compared to the previous runtime. In particular, <a class="reference external" href="https://furiosa-ai.github.io/docs/v0.10.0/en/api/python/furiosa.runtime.html#runner-api">worker_num</a>
configuration became more effective in FuriosaRT. For example, in the previous runtime,
higher than 2 <code class="docutils literal notranslate"><span class="pre">worker_num</span></code> did not show significant performance improvement in most cases.
However, in FuriosaRT, we observed that performance improvement is still significant even with <code class="docutils literal notranslate"><span class="pre">worker_num</span> <span class="pre">&gt;=</span> <span class="pre">10</span></code>.
We carried out benchmarking with Resnet50, YOLOv5m, YOLOv5L, SSD ResNet34, and SSD MobileNet models through
<code class="docutils literal notranslate"><span class="pre">furiosa-bench</span></code> command introduced in this release. We observed that performance improvement
is significantly up to tens of percent depending on the model with <code class="docutils literal notranslate"><span class="pre">worker_num</span> <span class="pre">&gt;=</span> <span class="pre">4</span></code>.</p>
</section>
</section>
<section id="model-server-and-serving-framework">
<h3>Model Server and Serving Framework<a class="headerlink" href="#model-server-and-serving-framework" title="Permalink to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">furiosa-server</span></code> and <code class="docutils literal notranslate"><span class="pre">furioa-serving</span></code> are a web server and a web framework respectively for serving models.
The improvements of FuriosaRT are also reflected to the model server and serving framework.</p>
<ul class="simple">
<li><p><a class="reference internal" href="#release-0-10-0-deviceselector"><span class="std std-ref">Multi-device Support and Improvement on Device Configuration</span></a> can be used to configure multiple NPU devices in <code class="docutils literal notranslate"><span class="pre">furiosa-server</span></code> and <code class="docutils literal notranslate"><span class="pre">furioa-serving</span></code></p></li>
<li><p>New <a class="reference external" href="https://docs.python.org/3/library/asyncio.html">asyncio</a>-based API that FuriosaRT offers is introduced to handle more concurrent requests with less resources.</p></li>
<li><p>The model server and serving framework inherit the performance characteristics of FuriosaRT. Also, more <code class="docutils literal notranslate"><span class="pre">worker_num</span></code> can be used to improve the performance of the model server.</p></li>
</ul>
<p>Please refer to <a class="reference internal" href="../software/serving.html#modelserving"><span class="std std-ref">Model Server (Serving Framework)</span></a> to learn more about the model server and serving framework.</p>
</section>
<section id="model-quantization-tool">
<h3>Model Quantization Tool<a class="headerlink" href="#model-quantization-tool" title="Permalink to this heading"></a></h3>
<p>The furiosa-quantizer is a library that transforms trained models into quantized models
through the post-training quantization. In 0.10.0 release,
the usability of the quantization tool has been improved,
so some parameters of the <code class="docutils literal notranslate"><span class="pre">furiosa.quantizer.quantize()</span></code> API have a few breaking changes.</p>
<section id="motivation-for-change">
<h4>Motivation for Change<a class="headerlink" href="#motivation-for-change" title="Permalink to this heading"></a></h4>
<p><code class="docutils literal notranslate"><span class="pre">furiosa.quantizer.quantize()</span></code> function is a core function of the model quantization tool.
<code class="docutils literal notranslate"><span class="pre">furiosa.quantizer.quantize()</span></code> transforms an ONNX model into a quantized model and returns it. The function has
the parameter <code class="docutils literal notranslate"><span class="pre">with_quantize</span></code> that allows the model to accept directly the <code class="docutils literal notranslate"><span class="pre">uint8</span></code> type
instead of <code class="docutils literal notranslate"><span class="pre">float32</span></code>, also enabling skipping the quantization process for inferences
when the original data type (e.g., pixel values) is uint8.
This option can result in significant performance improvements.
For instance, YOLOv5 Large with this option can dramatically reduce the execution time
from 60.639 ms to 0.277 ms.</p>
<p>Similarly, <code class="docutils literal notranslate"><span class="pre">normalized_pixel_outputs</span></code> option allows to directly use <code class="docutils literal notranslate"><span class="pre">unt8</span></code> type for outputs
instead of <code class="docutils literal notranslate"><span class="pre">float32</span></code>. This option can be useful when the model output is an image in RGB format
or when it can be directly used as an integer value. This option shows significant performance boosts.</p>
<p>In certain applications, two options can reduce execution time by several times to hundreds of times.
However, there were the following limitations and feedback:</p>
<ul class="simple">
<li><p>The parameter <code class="docutils literal notranslate"><span class="pre">normalized_pixel_outputs</span></code> was ambiguous in expressing the purpose clearly.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">normalized_pixel_outputs</span></code> assumes the output tensor value ranged from 0 to 1 in floating-point, and it had limited in real application.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">with_quantize</span></code> and <code class="docutils literal notranslate"><span class="pre">normalized_pixel_outputs</span></code> options only supported <code class="docutils literal notranslate"><span class="pre">uint8</span></code> type, and didn’t support <code class="docutils literal notranslate"><span class="pre">int8</span></code> type.</p></li>
</ul>
</section>
<section id="what-changed">
<h4>What Changed<a class="headerlink" href="#what-changed" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Removed the parameters <code class="docutils literal notranslate"><span class="pre">with_quantize</span></code> and <code class="docutils literal notranslate"><span class="pre">normalized_pixel_outputs</span></code> from <code class="docutils literal notranslate"><span class="pre">furiosa.quantizer.quantize()</span></code></p></li>
<li><dl class="simple">
<dt>Instead, added the class <a class="reference external" href="https://furiosa-ai.github.io/docs/v0.10.0/en/api/python/furiosa.quantizer.html#furiosa.quantizer.ModelEditor">ModelEditor</a>, allowing more options for model input/output types that offers following optimizations:</dt><dd><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">convert_input_type(tensor_name,</span> <span class="pre">TensorType)</span></code> method takes a tensor name, removes the corresponding quantize operator, and changes the input type to a given <code class="docutils literal notranslate"><span class="pre">TensorType</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">convert_output_type(tensor_name,</span> <span class="pre">TensorType,</span> <span class="pre">tensor_range)</span></code> method takes a tensor name, removes the corresponding dequantize operator, and changes the output type to <code class="docutils literal notranslate"><span class="pre">TensorType</span></code>, then modifies the scale of the model output to a given <code class="docutils literal notranslate"><span class="pre">tensor_range</span></code>.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Since the <code class="docutils literal notranslate"><span class="pre">convert_{output,input}_type</span></code> methods are based on tensor names, users should be able to find tensor names from an original ONNX model.</p></li>
</ul>
<p>For that, <code class="docutils literal notranslate"><span class="pre">furiosa.quantizer</span></code> module provides <code class="docutils literal notranslate"><span class="pre">get_pure_input_names(ModelProto)</span></code> and <code class="docutils literal notranslate"><span class="pre">get_output_names(ModelProto)</span></code> functions to retrieve tensor names from the original ONNX model.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The removal of <code class="docutils literal notranslate"><span class="pre">with_quantize</span></code>, <code class="docutils literal notranslate"><span class="pre">normalized_pixel_outputs</span></code> parameters from <code class="docutils literal notranslate"><span class="pre">furiosa.quantizer.quantize()</span></code>
is a breaking change that requires modifying existing code.</p>
</div>
<p>Please refer to <a class="reference external" href="https://furiosa-ai.github.io/docs/v0.10.0/en/api/python/furiosa.quantizer.html#furiosa.quantizer.ModelEditor">ModelEditor</a>
to learn more about the ModelEditor API and find examples from <a class="reference internal" href="../software/tutorials.html#tutorial"><span class="std std-ref">Tutorial and Code Examples</span></a>.</p>
</section>
</section>
<section id="compiler">
<h3>Compiler<a class="headerlink" href="#compiler" title="Permalink to this heading"></a></h3>
<p>Since this release, the compiler supports NPU acceleration for the <cite>Dequantize</cite> operator.
So, the latency or throughput of models that include <cite>Dequantize</cite> operators can be enhanced.
More details of this performance optimization can be found from <a class="reference internal" href="../software/performance.html#performanceoptimization"><span class="std std-ref">Performance Optimization</span></a>.</p>
<p>Since 0.10.0, the default lifetime of compiler cache has increased from 2 days to 30 days.
Please refer to <a class="reference internal" href="../software/compiler.html#compilercache"><span class="std std-ref">Compiler Cache</span></a> to learn the details of compiler cache feature.</p>
<p><code class="docutils literal notranslate"><span class="pre">furiosa-compiler</span></code> command in 0.10.0 release also has the following improvements:</p>
<ul class="simple">
<li><p>Add <code class="docutils literal notranslate"><span class="pre">furiosa-compiler</span></code> command in addition to <code class="docutils literal notranslate"><span class="pre">furiosa-compile</span></code> command</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">furiosa-compiler</span></code> and <code class="docutils literal notranslate"><span class="pre">furiosa-compile</span></code> commands as a native executable
and do not require any Python runtime environment.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">furiosa-compiler</span></code> is now available as an APT package, you can install via <code class="docutils literal notranslate"><span class="pre">apt</span> <span class="pre">install</span> <span class="pre">furiosa-compiler</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">furiosa</span> <span class="pre">compile</span></code> is kept for backward compatibility, and it will be removed in a future release.</p></li>
</ul>
<p>Please visit <a class="reference internal" href="../software/compiler.html#compilercli"><span class="std std-ref">furiosa-compiler</span></a> to learn more about <cite>furiosa-compiler</cite> command.</p>
</section>
<section id="performance-profiler">
<h3>Performance Profiler<a class="headerlink" href="#performance-profiler" title="Permalink to this heading"></a></h3>
<p>The performance profiler is a tool that helps users to analyze performance by measuring
the actual execution time of inferences.
Since 0.10.0, <a class="reference internal" href="../software/profiler.html#profilerenabledbycontext"><span class="std std-ref">Tracing via Profiler Context</span></a> API provides the pause/resume features.</p>
<p>This feature allows users to skip unnecessary steps like pre/post processing or warming up times,
leading to the reduction of the profiling overhead and the size of the profile result files.
Literally, calling <code class="docutils literal notranslate"><span class="pre">profile.pause()</span></code> method immediately stops the profliling, and
<code class="docutils literal notranslate"><span class="pre">profile.resume()</span></code> resumes the profiling again.
The profiler will not collect any profiling information between both method calls.
Please refer to <a class="reference internal" href="../software/profiler.html#temporarilydisablingprofiler"><span class="std std-ref">Pause/Resume of Profiler Context</span></a> to learn more about the profiling API.</p>
</section>
<section id="furiosa-litmus">
<h3>furiosa-litmus<a class="headerlink" href="#furiosa-litmus" title="Permalink to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">furiosa-litmus</span></code> is a command-line tool that checks the compatibility of models
with the NPU and Furiosa SDK. Since 0.10.0, <code class="docutils literal notranslate"><span class="pre">furiosa-litmus</span></code> has a new feature to collect
logs, profiling information, and an environment information for error reporting.
This feature is enabled if <code class="docutils literal notranslate"><span class="pre">--dump</span> <span class="pre">&lt;OUTPUT_PREFIX&gt;</span></code> option is specified.
The collected data is saved into a zip file named <code class="docutils literal notranslate"><span class="pre">&lt;OUTPUT_PREFIX&gt;-&lt;unix_epoch&gt;.zip</span></code>.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>furiosa-litmus<span class="w"> </span>&lt;MODEL_PATH&gt;<span class="w"> </span>--dump<span class="w"> </span>&lt;OUTPUT_PREFIX&gt;
</pre></div>
</div>
<p>The collected information does not include the model itself
but does contain only metadata of the model, memory usage, and environmental information
(e.g., Python version, SDK, compiler version, and dependency library versions).
You can directly unzip the zip file to check the contents.
When reporting bugs, attaching this file will be very helpful for error dianosis and analysis.</p>
</section>
<section id="new-benchmark-tool-furiosa-bench">
<h3>New Benchmark Tool ‘furiosa-bench’<a class="headerlink" href="#new-benchmark-tool-furiosa-bench" title="Permalink to this heading"></a></h3>
<p>The new benchmark tool, <code class="docutils literal notranslate"><span class="pre">furiosa-bench</span></code>, has been added since 0.10.0.
<code class="docutils literal notranslate"><span class="pre">furiosa-bench</span></code> command offers various options to run a diverse workloads with certain runtime settings.
Users can choose either latency-oriented or throughput-oriented workload, and can specify
the number of devices, how long time to run, and runtime settings. <code class="docutils literal notranslate"><span class="pre">furiosa-bench</span></code> accepts
both ONNX and Tflite models as well as an ENF file compiled by the furiosa-compiler.
More details about the command can be found at <a class="reference internal" href="../software/cli.html#furiosabench"><span class="std std-ref">furiosa-bench (Benchmark Tool)</span></a>.</p>
<p>An example of a throughput benchmark</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ furiosa-bench ./model.onnx --workload throughput -n 10000 --devices &quot;warboy(1)*2&quot; --workers 8 --batch 8
</pre></div>
</div>
<p>An example of a latency benchmark</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ furiosa-bench ./model.onnx --workload latency -n 10000 --devices &quot;warboy(2)*1&quot;
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">furiosa-bench</span></code> can be installed through apt package manager as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ apt install furiosa-bench
</pre></div>
</div>
</section>
<section id="furiosa-toolkit">
<h3>furiosa-toolkit<a class="headerlink" href="#furiosa-toolkit" title="Permalink to this heading"></a></h3>
<p>furiosa-toolkit is a collection of command line tools that provide NPU management and NPU device
monitoring. Since 0.10.0, <code class="docutils literal notranslate"><span class="pre">furiosa-toolkit</span></code> includes the following improvements:</p>
<p><strong>Improvements of furiosactl</strong></p>
<p>Before 0.10.0, the sub-commands like <code class="docutils literal notranslate"><span class="pre">list</span></code>, <code class="docutils literal notranslate"><span class="pre">info</span></code> print out a tabular text.
Since 0.10.0, <code class="docutils literal notranslate"><span class="pre">furiosactl</span></code> newly provides <code class="docutils literal notranslate"><span class="pre">--format</span></code> option, allowing to
print out the result in a structured format like <code class="docutils literal notranslate"><span class="pre">json</span></code> or <code class="docutils literal notranslate"><span class="pre">yaml</span></code>.
It will be useful when a users implements a shell pipeline or a script to process
the output of <code class="docutils literal notranslate"><span class="pre">furiosactl</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ furiosactl info --format json
[{&quot;dev_name&quot;:&quot;npu7&quot;,&quot;product_name&quot;:&quot;warboy&quot;,&quot;device_uuid&quot;:&quot;&lt;device_uuid&gt;&quot;,&quot;device_sn&quot;:&quot;&lt;device_sn&gt;&quot;,&quot;firmware&quot;:&quot;1.6.0, 7a3b908&quot;,&quot;temperature&quot;:&quot;47°C&quot;,&quot;power&quot;:&quot;0.99 W&quot;,&quot;pci_bdf&quot;:&quot;0000:d6:00.0&quot;,&quot;pci_dev&quot;:&quot;492:0&quot;}]

$ furiosactl info --format yaml
- dev_name: npu7
  product_name: warboy
  device_uuid: &lt;device_uuid&gt;
  device_sn: &lt;device_sn&gt;
  firmware: 1.6.0, 7a3b908
  temperature: 47°C
  power: 0.98 W
  pci_bdf: 0000:d6:00.0
  pci_dev: 492:0
</pre></div>
</div>
<p>Also, the subcommand <code class="docutils literal notranslate"><span class="pre">info</span></code> results in two more metrics:</p>
<ul class="simple">
<li><p>NPU Clock Frequency</p></li>
<li><p>Entire power consumption of card</p></li>
</ul>
<p><strong>Improvements of furiosa-npu-metrics-exporter</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">furiosa-npu-metrics-exporter</span></code> is a HTTP server to export NPU metrics and status
in <a class="reference external" href="https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md">OpenMetrics</a> format.
The metrics that <code class="docutils literal notranslate"><span class="pre">furiosa-npu-metrics-exporter</span></code>
exports can be collected by Prometheus and other OpenMetrics compatible collectors.</p>
<p>Since 0.10.0, <code class="docutils literal notranslate"><span class="pre">furiosa-npu-metrics-exporter</span></code> includes NPU clock frequency and NPU utilization
as metrics. NPU utilziation is still an experimental feature, and it is disabled by default.
To enable this feature, you need to specify <code class="docutils literal notranslate"><span class="pre">--enable-npu-utilization</span></code> option as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">furiosa</span><span class="o">-</span><span class="n">npu</span><span class="o">-</span><span class="n">metrics</span><span class="o">-</span><span class="n">exporter</span> <span class="o">--</span><span class="n">enable</span><span class="o">-</span><span class="n">npu</span><span class="o">-</span><span class="n">utilization</span>
</pre></div>
</div>
<p>Additionally, <code class="docutils literal notranslate"><span class="pre">furiosa-npu-metrics-exporter</span></code> is now available as an APT package
in addition to the docker image. You can install it as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">apt</span> <span class="n">install</span> <span class="n">furiosa</span><span class="o">-</span><span class="n">toolkit</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../api/python/furiosa.serving.processors.html" class="btn btn-neutral float-left" title="furiosa.serving.processors package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="0.9.0.html" class="btn btn-neutral float-right" title="Release Notes - 0.9.0" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023 FuriosaAI, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>